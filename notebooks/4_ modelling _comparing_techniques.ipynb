{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olist Product Recommendation System\n",
    "### Part 4 Modelling - Comparing Techniques\n",
    "#### Author: Olabisi Sunmon | 10th April 2023\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "How can we create a customised product recommendation system using data analysis and machine learning techniques to help Olist customers discover new products and find relevant items for purchase, to boost revenue and customer purchase rates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be exploring different collaborative filtering techniques to build a product recommendation system. I will compare the effectiveness of various algorithms and evaluate their performance using appropriate metrics.\n",
    "\n",
    "---------\n",
    "### Procedure:\n",
    "\n",
    "First time Customer recommendations will be based on;\n",
    "- Trending products in the country \n",
    "- Trending products in their state\n",
    "\n",
    "Returning Customer recommendations will be based on;\n",
    "- KNNWithMeans\n",
    "- FunkSVD \n",
    "- NormalPredictor\n",
    "- CoClustering\n",
    "\n",
    "These techniques have been published here; https://surpriselib.com\n",
    "\n",
    "------\n",
    "#### IMPORTANT \n",
    "Due to limitations in computational power, the modeling for returning customer product recommendation will be conducted on a subset of the dataset, rather than on the entire dataset.To ensure that the insights generated from the analysis are representative of the sales data at different levels of satisfaction, I will attempt to create a well-represented subset by stratifying the sample based on `review_score`. By doing so, the sample will contain a proportional representation of different satisfaction levels, which can help to ensure that the insights are generalized to the entire population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import Package\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Modeling\n",
    "from mlxtend.frequent_patterns import apriori, fpmax, fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from surprise import Dataset\n",
    "from surprise.reader import Reader\n",
    "from surprise import KNNWithMeans, CoClustering\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD as FunkSVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "\n",
    "#Ignore futurewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('/Users/labisi/Desktop/capstone-project-osunmon1/src/data/Processed/df_processed.pkl')\n",
    "returners = joblib.load('/Users/labisi/Desktop/capstone-project-osunmon1/src/data/Processed/returners_data.pkl')\n",
    "first_timers = joblib.load('/Users/labisi/Desktop/capstone-project-osunmon1/src/data/Processed/first_timer_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of returners dataset: (3476, 19)\n",
      "Shape of first timer dataset: (81785, 19)\n"
     ]
    }
   ],
   "source": [
    "# Creating a 30% subset of the returners dataframe\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.12, random_state=42)\n",
    "for _, test_index in split.split(returners, returners['review_score']):\n",
    "    returners = returners.iloc[test_index]\n",
    "    \n",
    "print(\"Shape of returners dataset:\", returners.shape)\n",
    "print(\"Shape of first timer dataset:\", first_timers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time Customer recommendations\n",
    "Trending products in the country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_items(df, top): #the function returns n trending items\n",
    "    top_n_items = df.product_id.value_counts().sort_values(ascending=False)[:top].index\n",
    "    return list(top_n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trending products in their state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def popular_state (df, state, top):#the function returns n trending items in the state\n",
    "    location_df = df[df.customer_state == state]\n",
    "    top_n_items = location_df.product_id.value_counts().sort_values(ascending=False)[:top].index\n",
    "    return list(top_n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function returns trending items in country and state of the customer\n",
    "\n",
    "def first_time_recommender(df, uid, top):\n",
    "    hot_items = popular_items(df, top)\n",
    "    state = df[df.customer_unique_id==uid].customer_state.max()\n",
    "    popular_in_state = popular_state(df, state, top)\n",
    "    \n",
    "    print(f\"Trending items you might like:\\n {hot_items}\\n\")\n",
    "    print(f\"Popular items in your area:\\n {popular_in_state}\")\n",
    "    \n",
    "    recommendation = {'Trending Items': hot_items, 'Area': popular_in_state}\n",
    "    \n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending items you might like:\n",
      " ['aca2eb7d00ea1a7b8ebd4e68314663af', '422879e10f46682990de24d770e7f83d', '99a4788cb24856965c36a24e339b6058']\n",
      "\n",
      "Popular items in your area:\n",
      " ['aca2eb7d00ea1a7b8ebd4e68314663af', '99a4788cb24856965c36a24e339b6058', '422879e10f46682990de24d770e7f83d']\n"
     ]
    }
   ],
   "source": [
    "# Example Recommendation\n",
    "recommendation = first_time_recommender(df, 'c71a196d46a70ec611f3922db5755d1d', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning Costumers\n",
    "### Collabrative Filtering \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating df\n",
    "collab_df =returners[['customer_unique_id','product_id','review_score']]\n",
    "collab_df = collab_df.sort_values(by=['customer_unique_id','product_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3476, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7f9d5ee33b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "# Set the dataset\n",
    "data = Dataset.load_from_df(collab_df, reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly i will be creating a model using FunkSVD\n",
    "\n",
    "Funk Singular Value Decomposition is a matrix factorization technique used in collaborative filtering recommendation systems to predict user preferences based on the feedback of similar users.\n",
    "\n",
    "Cross-validation will be set to 3 to avoid overfitting. The measure FCP will be used for the gridsearch as FCP evaluates the performance of a model in predicting user preferences. FCP ranges from -1 to 1, where 1 indicates perfect agreement between the predicted and actual rankings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [5, 150], \n",
    "    'n_epochs': [5, 40],\n",
    "    'lr_all': [0.0001, 0.1],\n",
    "    'biased': [False] }\n",
    "\n",
    "# Set 3 cross validation\n",
    "GS = GridSearchCV(FunkSVD, param_grid, measures=['fcp'], cv=3)\n",
    "\n",
    "# Fit the model\n",
    "GS.fit(data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1568627450980392"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the FCP accuracy score \n",
    "GS.best_score['fcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 5, 'n_epochs': 5, 'lr_all': 0.0001, 'biased': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best parameters\n",
    "GS.best_params['fcp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will tune funk SVD model using the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "# Set the SVD algorithm\n",
    "svd = FunkSVD(n_factors=5,n_epochs=5 ,lr_all=0.0001, biased=False, verbose=0)\n",
    "# Fit train set\n",
    "svd.fit(train)\n",
    "# Test the algorithm using test set\n",
    "pred = svd.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put my_pred result in a dataframe\n",
    "svd_pred_df = pd.DataFrame(pred, columns=['user_id','product_id','actual','prediction','details'])\n",
    "\n",
    "# Calculate the difference of actual and prediction into diff column\n",
    "svd_pred_df['diff'] = abs(svd_pred_df['prediction'] - \n",
    "                            svd_pred_df['actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f9d5ee332e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build full trainset\n",
    "train_df = data.build_full_trainset()\n",
    "\n",
    "# Build the SVD algorithm\n",
    "my_svd = FunkSVD(n_factors=5, n_epochs=5,lr_all=0.0001,biased=False, verbose=0)\n",
    "\n",
    "# Fit with full trainset\n",
    "my_svd.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full test set\n",
    "test_df = train_df.build_anti_testset(fill=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the prediction\n",
    "pred = my_svd.test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into a dataframe\n",
    "pred_df = pd.DataFrame(pred, columns=['user_id', 'product_id','actual', 'prediction','details'])                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create a FunkSVD recommendation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_FunkSVD(uid):\n",
    "    '''\n",
    "    Given a user_id, recommend new product using FunkSVD.\n",
    "    uid: user_id\n",
    "    '''\n",
    "    # check user_id prediction in pred_df\n",
    "    user_df = pred_df[pred_df['user_id'] == uid]\n",
    "    user_df = user_df.sort_values('prediction', ascending=False)\n",
    "    # merge with rating_df\n",
    "    df = user_df.merge(collab_df['product_id'].drop_duplicates(), how='left', \n",
    "                    on = 'product_id')\n",
    "    return df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>9e572ff4654f7064419d97a891a8b0fc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>1427b126f61597524866770b05d4eed2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>e731dfad79b4686d049d024b9fc97360</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>b3793f4676bdf327ca34c40d236ee2b2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>77cc62dc80ebe12a0452d1ce0565acdc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                        product_id  actual  \\\n",
       "0  66ae4493fc7c710a8db6d9620901f40d  9e572ff4654f7064419d97a891a8b0fc    -1.0   \n",
       "1  66ae4493fc7c710a8db6d9620901f40d  1427b126f61597524866770b05d4eed2    -1.0   \n",
       "2  66ae4493fc7c710a8db6d9620901f40d  e731dfad79b4686d049d024b9fc97360    -1.0   \n",
       "3  66ae4493fc7c710a8db6d9620901f40d  b3793f4676bdf327ca34c40d236ee2b2    -1.0   \n",
       "4  66ae4493fc7c710a8db6d9620901f40d  77cc62dc80ebe12a0452d1ce0565acdc    -1.0   \n",
       "\n",
       "   prediction                    details  \n",
       "0           1  {'was_impossible': False}  \n",
       "1           1  {'was_impossible': False}  \n",
       "2           1  {'was_impossible': False}  \n",
       "3           1  {'was_impossible': False}  \n",
       "4           1  {'was_impossible': False}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_FunkSVD('66ae4493fc7c710a8db6d9620901f40d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendation function has recommend 5 products for the user '66ae4493fc7c710a8db6d9620901f40d'. The actual value is -1 this shows that the user has not bought these items in the past. As the rating scale is from 1 - 5 a prediction rating of 1 indicates that the user is very likely to rate the item low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to evaluate a FunkSVD model is to look at its fcp score, FCP measures the proportion of pairs of data points for which the predicted values are in the same order as the actual values. This cannot be utilised because not all users have a minimum of two predictions. This situation may differ if we have used the whole dataset. When recommendation systems have more data to train on it can do a better job creating recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FCP\n",
    "# FCP = accuracy.fcp(pred, verbose=False)\n",
    "# print(fcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RMSE\n",
    "RMSE = accuracy.rmse(pred, verbose=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MAE\n",
    "MAE = accuracy.mae(pred, verbose=False)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE and the MAE score are 2, the lower the score the more accuarate the prediction of the rating. I will investage other recommendation systems againist FunkSVD using rmse score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Collaborating techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique has been explored here; https://surpriselib.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "algos = [FunkSVD(), KNNWithMeans(), NormalPredictor(),CoClustering()]\n",
    "for algo in algos:\n",
    "    # perform cross validation\n",
    "    results = cross_validate(algo, data, measures=['rmse'], cv=3, verbose=0)\n",
    "    # get results\n",
    "    temp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    temp = temp.append(pd.Series([str(algo).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    acc.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.516538</td>\n",
       "      <td>0.141338</td>\n",
       "      <td>0.006493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.525092</td>\n",
       "      <td>0.361644</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.533964</td>\n",
       "      <td>0.197952</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.018890</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.005964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "KNNWithMeans      1.516538  0.141338   0.006493\n",
       "CoClustering      1.525092  0.361644   0.004384\n",
       "SVD               1.533964  0.197952   0.006193\n",
       "NormalPredictor   2.018890  0.002890   0.005964"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results = pd.DataFrame(acc).set_index('Algorithm').sort_values('test_rmse')\n",
    "acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNNWithMeans has the best test_rmse score. I will now tune the KNNWithMeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Set the parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [5, 150], \n",
    "    'n_epochs': [5, 40],\n",
    "    'lr_all': [0.0001, 0.1],\n",
    "    'biased': [False] }\n",
    "\n",
    "# Set GridSearchCV with 3 cross validation\n",
    "GS = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# Fit the model\n",
    "GS.fit(data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.512998683665387"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_score['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 5, 'n_epochs': 5, 'lr_all': 0.0001, 'biased': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Check the best parameters\n",
    "GS.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test set\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "# Set the algorithm\n",
    "\n",
    "knn = KNNWithMeans(n_factors=5,\n",
    "              n_epochs=5 ,\n",
    "              lr_all=0.0001, \n",
    "              biased=False, \n",
    "              verbose=0)\n",
    "# Fit train set\n",
    "knn.fit(train)\n",
    "# Test the algorithm using test set\n",
    "pred = knn.test(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put my_pred result in a dataframe\n",
    "knn_pred_df = pd.DataFrame(pred, columns=['user_id',\n",
    "                                        'product_id',\n",
    "                                        'actual',\n",
    "                                        'prediction',\n",
    "                                        'details'])\n",
    "\n",
    "# Calculate the difference of actual and prediction into diff column\n",
    "knn_pred_df['diff'] = abs(knn_pred_df['prediction'] - \n",
    "                            knn_pred_df['actual'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7f9a1b0f3b50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build full trainset\n",
    "train_df = data.build_full_trainset()\n",
    "\n",
    "# Build the SVD algorithm\n",
    "my_knn = KNNWithMeans(n_factors=5, \n",
    "                 n_epochs=5, \n",
    "                 lr_all=0.0001,    \n",
    "                 biased=False, \n",
    "                 verbose=0)\n",
    "\n",
    "# Fit with full trainset\n",
    "my_knn.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full test set\n",
    "test_df = train_df.build_anti_testset(fill=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the prediction\n",
    "pred = my_knn.test(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into a dataframe\n",
    "pred_df = pd.DataFrame(pred, columns=['user_id', 'product_id','actual', 'prediction','details'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_knn(uid):\n",
    "    '''\n",
    "    Given a user_id, recommend new product using KNN.\n",
    "    uid: user_id\n",
    "    '''\n",
    "    # check user_id prediction in pred_df\n",
    "    user_df = pred_df[pred_df['user_id'] == uid]\n",
    "    user_df = user_df.sort_values('prediction', ascending=False)\n",
    "    # merge with rating_df\n",
    "    df = user_df.merge(collab_df['product_id'].drop_duplicates(), how='left', \n",
    "                    on = 'product_id')\n",
    "    return df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>9e572ff4654f7064419d97a891a8b0fc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>1427b126f61597524866770b05d4eed2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>e731dfad79b4686d049d024b9fc97360</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>b3793f4676bdf327ca34c40d236ee2b2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66ae4493fc7c710a8db6d9620901f40d</td>\n",
       "      <td>77cc62dc80ebe12a0452d1ce0565acdc</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'actual_k': 0, 'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                        product_id  actual  \\\n",
       "0  66ae4493fc7c710a8db6d9620901f40d  9e572ff4654f7064419d97a891a8b0fc    -1.0   \n",
       "1  66ae4493fc7c710a8db6d9620901f40d  1427b126f61597524866770b05d4eed2    -1.0   \n",
       "2  66ae4493fc7c710a8db6d9620901f40d  e731dfad79b4686d049d024b9fc97360    -1.0   \n",
       "3  66ae4493fc7c710a8db6d9620901f40d  b3793f4676bdf327ca34c40d236ee2b2    -1.0   \n",
       "4  66ae4493fc7c710a8db6d9620901f40d  77cc62dc80ebe12a0452d1ce0565acdc    -1.0   \n",
       "\n",
       "   prediction                                   details  \n",
       "0         5.0  {'actual_k': 0, 'was_impossible': False}  \n",
       "1         5.0  {'actual_k': 0, 'was_impossible': False}  \n",
       "2         5.0  {'actual_k': 0, 'was_impossible': False}  \n",
       "3         5.0  {'actual_k': 0, 'was_impossible': False}  \n",
       "4         5.0  {'actual_k': 0, 'was_impossible': False}  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender_knn('66ae4493fc7c710a8db6d9620901f40d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the KNN recommendation system and FunkSVD recommendation system both recommended the same 5 products for customer '66ae4493fc7c710a8db6d9620901f40d',  the  predicted ratings for the KKN recommendation is much higher at 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9583506772736206"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "RMSE = accuracy.rmse(pred, verbose=False)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7006990680466405\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MAE\n",
    "MAE = accuracy.mae(pred, verbose=False)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the tuned FunkSVD model and the tuned KNN model\n",
    "\n",
    "Although the untuned KNN algorithm had the best test RMSE score when compared to CoClustering, FunkSVD, and NormalPredictor algorithms, the tuned FunkSVD algorithm outperformed the tuned KNN algorithm with an RMSE of 2, while the KNN algorithm had an RMSE of 5.\n",
    "\n",
    "The reason for the difference in performance between KNN and FunkSVD algorithms may be because they work in very different ways. KNN algorithms struggle with sparse matrices, as they do not assume any underlying data distribution, while FunkSVD algorithm assumes that the data can be represented as a low-rank matrix. Which could of resulted in the FunkSVD model performing better than KNN model on unseen test data.\n",
    "\n",
    "https://medium.com/analytics-vidhya/k-nearest-neighbors-all-you-need-to-know-1333eb5f0ed0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item - Item \n",
    "An item-item based collaborative recommendation system was attempted, but due to the wide range of over 32000 products and a low average purchase rate of unique products per costumer, it faced difficulties. The system struggled to identify similar items accordingly because there were very few pairwise arrays available, making the task extremely challenging and therefore making that recommendation system redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook 3_modelling_comparing_market_basket I have developed a product recommendation system that suggests products to customers based on the items in their basket. As Olist's order history data grows, it would be beneficial for the business to explore product recommendations based on the customer state and/or product categories of items in their basket. This could provide a more personalised recommendation if trends are found.\n",
    "\n",
    "It's important to note that when creating a collaborative filtering-based product recommendation system, choosing a model with the lowest test_RSME score isn't enough. It's crucial to understand how the model will work with the available order data. I recommend that Olist considers user-based recommendations using the FunkSVD recommendation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_ml",
   "language": "python",
   "name": "bigdata_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "99fd51de5e5cc81fcf5dc2ed924ae715b26357f803e3dbd20b5930e53d5ef3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
